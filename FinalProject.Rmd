---
title: "Final Project"
author: "Kishan Thambu and Anisa Habib"
date: "5/4/2022"
output: html_document
---

```{r setup, include=FALSE}
# Installed/Required Packages 
# Geosphere (Required for calculating store distance)
# https://cran.r-project.org/web/packages/geosphere/vignettes/geosphere.pdf
library ("geosphere")
library("ggplot2")
```

# Introduction

For several decades, health officials have encouraged people to eat more nutritious foods like fruits and vegetables and avoid junk or processed foods like chips and fast food in order to maintain a healthy diet and prevent several diseases and other health issues. However, for many families in the United States, access to these healthy foods are hard to even access. This lack of access to healthy food resources is just one aspect of what is known as a "food desert". A food desert is an area that has limited access to affordable and nutritious food. These areas tend to be inhabited by low-income residents with reduced mobility, which makes them less attractive markets for large supermarket chains, causing the location to lack suppliers of fresh foods. Instead, processed food and food high in sugar and fats, which are known contributors to the proliferation of obesity in the US, are more readily available for consumption. In contrast, an area with higher access to supermarkets or vegetable shops with fresh foods is called a food oasis. The designation considers the type and the quality of food available to the population, in addition to the accessibility of the food through the size and the proximity of the food stores. In 2010, the United States Department of Agriculture reported that 23.5 million people in the US live in these "food deserts," low-income census tracts that are more than 1 mile (1609.34 meters) from a supermarket in urban or suburban areas and more than 10 miles (16093.4 meters) from a supermarket in rural areas. In this study, we aim to *explore to what extent food deserts exist in various cities throughout the state of Utah*.

## Data Sources

To answer this projects research question, we used store distance and store type data from Google Maps. Furthermore, we will also be interpreting population, median household income, and vehicle registration data from the US Census Bureau. More specifically, our data set includes variables for city, population, city type (urban or rural), store, store type, latitude and longitude, median household income, and number of total registered vehicles. The latitude and longitude points will be used to calculate distance between other stores by city. 

## Data Collection and Methodology

The methodology for the collection of data in this study was built around the availability of store and census data and the research question.

After brainstorming and narrowing down our question, we began the data collection phase of our project. To collect data, 10 random cities in Utah were selected from The World Population review's list of Utah cities by population. 5 random urban cities and 5 random rural cities were selected; these categories were determined by defining any city with a 2022 population below 20,000 as rural. The final cities selected were Salt Lake City, Provo, Logan, Ogden, South Jordan, Farmington, Woods Cross, Roosevelt, Morgan, and Wellington. Once the cities were collected, we collected data on that city's respective population, median household income, and registered vehicles. Grocery store data was gathered from the Google Maps free service. A random store from one of the cities chosen was selected, and information about the store name, store type, longitude, and latitude. There were three possible store types- convenience store, grocery store, or organic grocery store. This was repeated until each city had 5 store points respectively.  Once the dataset was completed, we decided to follow the following methodology for collecting and analyzing the data in a way that would best answer the questions of this study. 

Including the above steps, we followed the following methodology to gain a better understanding of the data and compute relevant analyses:

1. Operationalize the research question into one that is actually quantifiable.
   + We need a question about a population parameter that we can estimate with a sample statistic.
2. Identify an appropriate sampling strategy.
   + Collect data on 5 random stores from 10 random cities (5 urban, 5 rural)
3. Identify the appropriate probability distribution.
   + The central limit theorem (CLT): under broad conditions the sampling distribution of the mean converges to normal.
4. Compute a margin of error so that there is a (1 - Î±) probability of getting a sample statistic within that margin of the population parameter.
   + For the relevant sample statistic, we plan to take a $95%$ two-sided confidence interval.
5. Compute the relevant sample statistics.
   + Compute average distance between stores using *Geosphere* R package
   + Compute average store type
6. Create the relevant summary figures.
   + Create a bar plot for each variable with bars to represent each city, and an indication of whether the city is urban or rural.
   + Create histograms for relevant variables.
3. Arithmetic the margin of error around the sample statistic to find likely locations of the population parameter.
4. Provide a context-appropriate interpretation of the confidence and bounds.

We decided to choose a confidence level of 95%. This confidence is "moderately" or "pretty" strong and chosen with consideration of the limited number of stations used for sample data collection.

## Initial Data Summaries

To start analyzing the collected data, the csv files were read into RStudio.

```{r}
# read in data
healthfooddata <- read.csv("healthfooddata.csv")
# filter data
slc_data <- healthfooddata[which(healthfooddata$city == 'Salt Lake City'),]
provo_data <- healthfooddata[which(healthfooddata$city == 'Provo'),]
sj_data <- healthfooddata[which(healthfooddata$city == 'South Jordan'),]
orem_data <- healthfooddata[which(healthfooddata$city == 'Orem'),]
logan_data <- healthfooddata[which(healthfooddata$city == 'Logan'),]
wellington_data <- healthfooddata[which(healthfooddata$city == 'Wellington'),]
morgan_data <- healthfooddata[which(healthfooddata$city == 'Morgan'),]
farmington_data <- healthfooddata[which(healthfooddata$city == 'Farmington'),]
roosevelt_data <- healthfooddata[which(healthfooddata$city == 'Roosevelt'),]
woodscross_data <- healthfooddata[which(healthfooddata$city == 'Woods Cross'),]
```

Preliminary summary statistics are generated by the R code below:

```{r}
# data summaries
summary(slc_data)
summary(provo_data)
summary(sj_data)
summary(orem_data)
summary(logan_data)
summary(wellington_data)
summary(morgan_data)
summary(farmington_data)
summary(roosevelt_data)
summary(woodscross_data)
```

 A plot on population is generated by the R code below:

```{r}
# population plot
totalPopulations <- c(slc_data$population[1], provo_data$population[1], sj_data$population[1], orem_data$population[1],
                      logan_data$population[1], wellington_data$population[1], morgan_data$population[1], farmington_data$population[1],
                      roosevelt_data$population[1], woodscross_data$population[1])
barplot(totalPopulations, 
        names.arg = c("SLC", "Provo", "South Jordan", "Orem", "Logan", "Wellington", "Morgan", "Farmington", "Roosevelt", "Woods Cross"), 
        xlab = "Cities",
        ylab = "Number Of People", 
        main = "Population Bar Plot", 
        col=c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright",                                    # Add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))
```


Next, we created a similar plot for the median income variable

```{r}
# median income plot
totalMedianIncome <- c(slc_data$median.household.income[1], provo_data$median.household.income[1], 
                       sj_data$median.household.income[1], orem_data$median.household.income[1], logan_data$median.household.income[1], 
                       wellington_data$median.household.income[1], morgan_data$median.household.income[1], farmington_data$median.household.income[1], 
                       roosevelt_data$median.household.income[1], woodscross_data$median.household.income[1])
barplot(totalMedianIncome, 
        names.arg = c("SLC", "Provo", "South Jordan", "Orem", "Logan", "Wellington", "Morgan", "Farmington", "Roosevelt", "Woods Cross"), 
        xlab = "Cities", 
        ylab = "Median Income by Dollar", 
        main = "Medium Income Bar Plot", 
        col=c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright",                                    # Add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))
```

As the definition of a food desert explains the distance between grocery stores in a certain area, the next step was to calculate the average distance between stores. This was completed through use of the Geosphere R package (https://cran.r-project.org/web/packages/geosphere/vignettes/geosphere.pdf) as it contains methods to calculate the distance between two latitude-longitude points. The average distance was calculated with the following arithmetic:

```{r}
# calculating average store distance for each city from longitude and latitude
# initialize distance arrays
slcdist <- replicate(10,0)
logandist <- replicate(10,0)
provodist <- replicate(10,0)
oremdist <- replicate(10,0)
sjdist <- replicate(10,0)
farmingtondist <- replicate(10,0)
morgandist <- replicate(10,0)
wellingtondist <- replicate(10,0)
rooseveltdist <- replicate(10,0)
woodscrossdist <- replicate(10,0)

# loop through and calculate distances between all store variations
i = 0 # which index in distance arrays to change
for (x in 1:5) { # for each store
  nextStore = x + 1 # get index of the store to compare to
  if (nextStore == 6)
    next
  for (y in nextStore:5) { # calculate distance between other stores (that haven't already been calculated)
      i = i + 1 # increment index
      slcdist[i] <- distHaversine(c(slc_data$longitude[x], slc_data$latitude[x]),
                           c(slc_data$longitude[y], slc_data$latitude[y]))
      logandist[i] <- distHaversine(c(logan_data$longitude[x], logan_data$latitude[x]),
                           c(logan_data$longitude[y], logan_data$latitude[y]))
      provodist[i] <- distHaversine(c(provo_data$longitude[x], provo_data$latitude[x]),
                           c(provo_data$longitude[y], provo_data$latitude[y]))
      oremdist[i] <- distHaversine(c(orem_data$longitude[x], orem_data$latitude[x]),
                           c(orem_data$longitude[y], orem_data$latitude[y]))
      sjdist[i] <- distHaversine(c(sj_data$longitude[x], sj_data$latitude[x]),
                           c(sj_data$longitude[y], sj_data$latitude[y]))
      farmingtondist[i] <- distHaversine(c(farmington_data$longitude[x], farmington_data$latitude[x]),
                     c(farmington_data$longitude[y], farmington_data$latitude[y]))
      morgandist[i] <- distHaversine(c(morgan_data$longitude[x], morgan_data$latitude[x]),
                           c(morgan_data$longitude[y], morgan_data$latitude[y]))
      wellingtondist[i] <- distHaversine(c(wellington_data$longitude[x], wellington_data$latitude[x]),
                           c(wellington_data$longitude[y], wellington_data$latitude[y]))
      rooseveltdist[i] <- distHaversine(c(roosevelt_data$longitude[x], roosevelt_data$latitude[x]),
                           c(roosevelt_data$longitude[y], roosevelt_data$latitude[y]))
      woodscrossdist[i] <- distHaversine(c(woodscross_data$longitude[x], woodscross_data$latitude[x]),
                           c(woodscross_data$longitude[y], woodscross_data$latitude[y]))
  }
}
```



```{r}
# store all average distances in a new array
all_avg_distances <- c(mean(slcdist), mean(logandist), mean(provodist), mean(oremdist), mean(sjdist), mean(farmingtondist),
                      mean(wellingtondist), mean(morgandist), mean(rooseveltdist), mean(woodscrossdist))
all_avg_distances

# distance plot
barplot(all_avg_distances, 
        names.arg = c("SLC", "Provo", "South Jordan", "Orem", "Logan", "Wellington", "Morgan", "Farmington", "Roosevelt", "Woods Cross"), 
        xlab = "Cities",
        ylab = "Distance in Meters (m)", 
        main = "Average Distance between stores", 
        col=c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright",  # add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))

# total average distances histogram - How does store distance behave for all of Utah?
lattice::histogram(all_avg_distances, breaks = 10,
                   main = paste("Total Average Distances Histogram"),
                   xlab = "Store Distance in Meters (m)")
```


```{r}
# store total number of store types per city
saltlakecityTotalStoreTypes <- c(length(slc_data[which(slc_data$store.type == 'Organic Grocery Store'),6]), 
                                 length(slc_data[which(slc_data$store.type == 'Grocery Store'),6]), 
                                 length(slc_data[which(slc_data$store.type == 'Convenience Store'),6]))

provoTotalStoreTypes <- c(length(provo_data[which(provo_data$store.type == 'Organic Grocery Store'),6]),
                          length(provo_data[which(provo_data$store.type == 'Grocery Store'),6]),
                          length(provo_data[which(provo_data$store.type == 'Convenience Store'),6]))

southjordanTotalStoreTypes <- c(length(sj_data[which(sj_data$store.type == 'Organic Grocery Store'),6]), 
                                length(sj_data[which(sj_data$store.type == 'Grocery Store'),6]), 
                                length(sj_data[which(sj_data$store.type == 'Convenience Store'),6]))

oremTotalStoreTypes <- c(length(orem_data[which(orem_data$store.type == 'Organic Grocery Store'),6]), 
                         length(orem_data[which(orem_data$store.type == 'Grocery Store'),6]), 
                         length(orem_data[which(orem_data$store.type == 'Convenience Store'),6]))

loganTotalStoreTypes <- c(length(logan_data[which(logan_data$store.type == 'Organic Grocery Store'),6]), 
                          length(logan_data[which(logan_data$store.type == 'Grocery Store'),6]), 
                          length(logan_data[which(logan_data$store.type == 'Convenience Store'),6]))

wellingtonTotalStoreTypes <- c(length(wellington_data[which(wellington_data$store.type == 'Organic Grocery Store'),6]), 
                               length(wellington_data[which(wellington_data$store.type == 'Grocery Store'),6]), 
                               length(wellington_data[which(wellington_data$store.type == 'Convenience Store'),6]))

morganTotalStoreTypes <- c(length(morgan_data[which(morgan_data$store.type == 'Organic Grocery Store'),6]), 
                           length(morgan_data[which(morgan_data$store.type == 'Grocery Store'),6]), 
                           length(morgan_data[which(morgan_data$store.type == 'Convenience Store'),6]))

farmingtonTotalStoreTypes <- c(length(farmington_data[which(farmington_data$store.type == 'Organic Grocery Store'),6]), 
                               length(farmington_data[which(farmington_data$store.type == 'Grocery Store'),6]), 
                               length(farmington_data[which(farmington_data$store.type == 'Convenience Store'),6]))

rooseveltTotalStoreTypes <- c(length(roosevelt_data[which(roosevelt_data$store.type == 'Organic Grocery Store'),6]), 
                              length(roosevelt_data[which(roosevelt_data$store.type == 'Grocery Store'),6]), 
                              length(roosevelt_data[which(roosevelt_data$store.type == 'Convenience Store'),6]))

woodscrossTotalStoreTypes <- c(length(woodscross_data[which(woodscross_data$store.type == 'Organic Grocery Store'),6]), 
                               length(woodscross_data[which(woodscross_data$store.type == 'Grocery Store'),6]), 
                               length(woodscross_data[which(woodscross_data$store.type == 'Convenience Store'),6]))

# combine vectors using c bind function
totalStoreTypes <- cbind(saltlakecityTotalStoreTypes, provoTotalStoreTypes, southjordanTotalStoreTypes, oremTotalStoreTypes, 
                         loganTotalStoreTypes, wellingtonTotalStoreTypes, morganTotalStoreTypes, farmingtonTotalStoreTypes, 
                         rooseveltTotalStoreTypes, woodscrossTotalStoreTypes)
# plot total store types
barplot(totalStoreTypes , beside=T, 
        names.arg = c("SLC", "Provo", "South Jordan", "Orem", "Logan", "Wellington", "Morgan", "Farmington", "Roosevelt", "Woods Cross"), 
        xlab = "Cities",
        ylab = "Stores", 
        main = "Store Types Found in Each City", 
        col=c("#1b98e0", "#111111", "#aaaaaa"), las = 3)
# add legend to bar plot
legend("topright",
       legend = c("Organic Grocery Store", "Grocery Store", "Convenience Store"),
       fill = c("#1b98e0", "#111111", "#aaaaaa"))
```

## Confidence Interval on Distance between stores

```{r}
# 95% confidence level - How confident are we that the mean of our sample is an accurate representation of the true population?
t.test(slcdist, conf.level = 0.95)
t.test(logandist, conf.level = 0.95)
t.test(provodist, conf.level = 0.95)
t.test(oremdist, conf.level = 0.95)
t.test(sjdist, conf.level = 0.95)
t.test(farmingtondist, conf.level = 0.95)
t.test(morgandist, conf.level = 0.95)
t.test(wellingtondist, conf.level = 0.95)
t.test(rooseveltdist, conf.level = 0.95)
t.test(woodscrossdist, conf.level = 0.95)
```


```{r}
# create data frame combining all dist
all_distances <- data.frame(SLC = slcdist, LOGAN = logandist, PROVO = provodist, OREM = oremdist, SOUTHJORDAN = sjdist, 
                            FARMINGTON = farmingtondist, MORGAN = morgandist, WELLINGTON = wellingtondist, 
                            ROOSEVELT = rooseveltdist, WOODSCROSS = woodscrossdist)

# calculate conf intervals between all cities store distances - How confident are we that one city actually has a larger between-store distance than another?
all_distances_cis <- apply(all_distances, 1, function(x){t.test(x, conf.level = 0.95)})

# check for overlap 
df1 <- read.table(text = 
" City	lowerci	Estimate	upperci
SLC	392	1912.751	3433
Logan	1838	4583.664	7392
Provo	748	3607.293	6467
Orem	459	3003.557	5548
SouthJordan	1161	3857.936	6555
Farmington	662	3537.668	6413
Morgan	591	3263.311	5936
Wellington	1462	4370.249	1285.814
Roosevelt	1830	3844.588	5859
WoodsCross	834	3067.96	6969                 
", header = TRUE, as.is = TRUE)

ggplot(df1, aes(x = City, y = Estimate, ymin = lowerci, ymax = upperci)) +
  geom_pointrange()
```




