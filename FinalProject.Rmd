---
title: "To what extent do food deserts exist in various cities in the state of Utah?"
author: "Kishan Thambu and Anisa Habib"
date: "5/3/2022"
output: html_document
---

```{r setup, include=FALSE}
# Installed/Required Packages 
# Geosphere (Required for calculating store distance)
# https://cran.r-project.org/web/packages/geosphere/vignettes/geosphere.pdf
library ("geosphere")
library("ggplot2")
```

## Introduction

For several decades, health officials have encouraged people to eat more nutritious foods like fruits and vegetables and avoid junk or processed foods like chips and fast food in order to maintain a healthy diet and prevent several diseases and other health issues. However, for many families in the United States, access to these healthy foods are hard to even access. This lack of access to healthy food resources is just one aspect of what is known as a "food desert". A food desert is an area that has limited access to affordable and nutritious food. These areas tend to be inhabited by low-income residents with reduced mobility, which makes them less attractive markets for large supermarket chains, causing the location to lack suppliers of fresh foods. Instead, processed food and food high in sugar and fats, which are known contributors to the proliferation of obesity in the US, are more readily available for consumption. In contrast, an area with higher access to supermarkets or vegetable shops with fresh foods is called a food oasis. The designation considers the type and the quality of food available to the population, in addition to the accessibility of the food through the size and the proximity of the food stores. In 2010, the United States Department of Agriculture reported that 23.5 million people in the US live in these "food deserts," low-income census tracts that are more than 1 mile (1609.34 meters) from a supermarket in urban or suburban areas and more than 10 miles (16093.4 meters) from a supermarket in rural areas. In this study, we aim to explore *to what extent food deserts exist in various cities throughout the state of Utah*.

## Data Sources

To answer this projects research question, we used store distance and store type data from Google Maps. Furthermore, we will also be interpreting population, median household income, and vehicle registration data from the US Census Bureau. More specifically, our data set includes variables for city, population, city type (urban or rural), store, store type, latitude and longitude, median household income, and number of total registered vehicles. The latitude and longitude points will be used to calculate distance between other stores by city. 

## Data Collection and Methodology

The methodology for the collection of data in this study was built around the availability of store and census data and the research question.

After brainstorming and narrowing down our question, we began the data collection phase of our project. To collect data, 10 random cities in Utah were selected from The World Population review's list of Utah cities by population. 5 random urban cities and 5 random rural cities were selected; these categories were determined by defining any city with a 2022 population below 20,000 as rural. The final cities selected were Salt Lake City, Provo, Logan, Ogden, South Jordan, Farmington, Woods Cross, Roosevelt, Morgan, and Wellington. Once the cities were collected, we collected data on that city's respective population, median household income, and registered vehicles. Grocery store data was gathered from the Google Maps free service. A random store from one of the cities chosen was selected, and information about the store name, store type, longitude, and latitude. There were three possible store types- convenience store, grocery store, or organic grocery store. This was repeated until each city had 5 store points respectively.  Once the dataset was completed, we decided to follow the following methodology for collecting and analyzing the data in a way that would best answer the questions of this study. 

Including the above steps, we followed the following methodology to gain a better understanding of the data and compute relevant analyses:

1. Operationalize the research question into one that is actually quantifiable.
   + We need a question about a population parameter that we can estimate with a sample statistic.
2. Identify an appropriate sampling strategy.
   + Collect data on 5 random stores from 10 random cities (5 urban, 5 rural)
3. Identify the appropriate probability distribution.
   + The central limit theorem (CLT): under broad conditions the sampling distribution of the mean converges to normal.
4. Compute a margin of error so that there is a (1 - Î±) probability of getting a sample statistic within that margin of the population parameter.
   + For the relevant sample statistic, we plan to take a **95%** two-sided confidence interval.
5. Compute the relevant sample statistics.
   + Compute average distance between stores using *Geosphere* R package
   + Compute average store type
6. Create the relevant summary figures.
   + Create a bar plot for each variable with bars to represent each city, and an indication of whether the city is urban or rural.
   + Create histograms for relevant variables.
3. Arithmetic the margin of error around the sample statistic to find likely locations of the population parameter.
4. Provide a context-appropriate interpretation of the confidence and bounds.

We decided to choose a confidence level of 95%. This confidence is "moderately" or "pretty" strong and chosen with consideration of the limited number of stations used for sample data collection.

## Initial Data Summaries

To start analyzing the collected data, the csv files were read into RStudio.

```{r}
# read in data
healthfooddata <- read.csv("healthfooddata.csv")
# filter data
slc_data <- healthfooddata[which(healthfooddata$city == 'Salt Lake City'),]
provo_data <- healthfooddata[which(healthfooddata$city == 'Provo'),]
sj_data <- healthfooddata[which(healthfooddata$city == 'South Jordan'),]
orem_data <- healthfooddata[which(healthfooddata$city == 'Orem'),]
logan_data <- healthfooddata[which(healthfooddata$city == 'Logan'),]
wellington_data <- healthfooddata[which(healthfooddata$city == 'Wellington'),]
morgan_data <- healthfooddata[which(healthfooddata$city == 'Morgan'),]
farmington_data <- healthfooddata[which(healthfooddata$city == 'Farmington'),]
roosevelt_data <- healthfooddata[which(healthfooddata$city == 'Roosevelt'),]
woodscross_data <- healthfooddata[which(healthfooddata$city == 'Woods Cross'),]
```

Once all the data was read in, preliminary summary statistics were generated by the R code below:

```{r}
# data summaries
summary(slc_data)
summary(provo_data)
summary(sj_data)
summary(orem_data)
summary(logan_data)
summary(wellington_data)
summary(morgan_data)
summary(farmington_data)
summary(roosevelt_data)
summary(woodscross_data)
```

Here, we can see each dataset has columns for population, city type, store, store type, latitude, longitude, and median household income. To best answer the question of whether each city may be considered as a food desert, it is most reasonable to look at population, median household income, store type amounts, and distance between stores. 

## Data Analysis

# Population and Median Income

The first statistic that our data deals with is population per city. In order to gain a better understanding of how this data behaves and what types of population we are actually comparing, we decided to create some visual representation of all the data. A bar plot on total population per city is generated by the R code below:

```{r}
# population plot
totalPopulations <- c(slc_data$population[1], provo_data$population[1], orem_data$population[1], sj_data$population[1],
                      logan_data$population[1], farmington_data$population[1], woodscross_data$population[1], roosevelt_data$population[1],
                      morgan_data$population[1], wellington_data$population[1])
par(mar = c(5.1, 4.1, 4.1, 8.1), xpd=TRUE) # add extra space outside of plot
barplot(totalPopulations, 
        names.arg = c("SLC", "Provo", "Orem", "S. Jordan", "Logan", "Farmington", "Woods Cross", "Roosevelt", "Morgan", "Wellington"), 
        xlab = "Cities",
        ylab = "Number Of People", 
        main = "Total Population per City", 
        col=c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright", inset=c(-0.2,0),        # add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))
```

Here, we can see that the cities we classified as "urban" have much higher populations than the cities we classified as "rural", with SLC having the highest total population and Wellington having the lowest total population. This is expected because we defined urban cities as those with a population above 20,000 and rural cities as those with a population below 20,000. We expect urban cities to have a much higher average population, and this plot displays that. The population statistic is important in reference to the definition of a food desert as it may help us determine how developed an area is. If a city has a high enough population to be considered as urban we would expect much more infrastructure in that location since there is a much larger market. So, we would expect greater number of grocery stores and a wider variety of grocery store types in urban cities than rural ones. 

Next, we created a similar plot for the median household income variable:

```{r}
# median income plot
totalMedianIncome <- c(slc_data$median.household.income[1], provo_data$median.household.income[1], 
                       orem_data$median.household.income[1], sj_data$median.household.income[1], logan_data$median.household.income[1], 
                       farmington_data$median.household.income[1], woodscross_data$median.household.income[1], roosevelt_data$median.household.income[1], 
                       morgan_data$median.household.income[1], wellington_data$median.household.income[1])
par(mar = c(5.1, 4.1, 4.1, 8.1), xpd=TRUE) # add extra space outside of plot
barplot(totalMedianIncome, 
        names.arg = c("SLC", "Provo", "Orem", "S. Jordan", "Logan", "Farmington", "Woods Cross", "Roosevelt", "Morgan", "Wellington"),  
        xlab = "Cities", 
        ylab = "Median Income in USD", 
        main = "Median Household Income per City", 
        col = c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright", inset=c(-0.2,0),        # add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))
```

Here, we can see much more "uniform" distribution of the median household income variable. One might expect that cities classified as rural would have a much lower median household income than cities classified as urban. However, according to the bar plot of our data, this is not the case. We can see much higher values of median household income in some rural cities compared to large urban ones- such as Farmington versus SLC. One reason this could be is because there are a lot of neighboring cities to Salt Lake City. People could be living in one city but commuting to another for work- however, the median household income variable does not take such factors into account. It is important to note that poverty rates may also affect this statistic; cities with higher populations may have a greater number of people that are below the poverty line. This would bring down the total median income of that city, and this statistic and this study does not take poverty rates into account.

Looking into median household income can provide further insight into store accessibility. If cities on average are making much less than other cities, we can infer that the residents likely have fewer access to transportation resources. This also influences more convenience stores and less supermarket and grocery stores for that area. Median Household income is a possible variable that contributes to store accessibility and store types inherently affecting food deserts. 

# Distance Between Stores

As the definition of a food desert explains the distance between grocery stores in a certain area, the next step was to calculate the average distance between stores. This was completed through use of the Geosphere R package (https://cran.r-project.org/web/packages/geosphere/vignettes/geosphere.pdf) as it contains methods to calculate the distance between two latitude-longitude points. The average distance was calculated with the following arithmetic:

```{r}
# calculating average store distance for each city from longitude and latitude
# initialize distance arrays
slcdist <- replicate(10,0)
logandist <- replicate(10,0)
provodist <- replicate(10,0)
oremdist <- replicate(10,0)
sjdist <- replicate(10,0)
farmingtondist <- replicate(10,0)
morgandist <- replicate(10,0)
wellingtondist <- replicate(10,0)
rooseveltdist <- replicate(10,0)
woodscrossdist <- replicate(10,0)

# loop through and calculate distances between all store variations
i = 0 # which index in distance arrays to change
for (x in 1:5) { # for each store
  nextStore = x + 1 # get index of the store to compare to
  if (nextStore == 6)
    next
  for (y in nextStore:5) { # calculate distance between other stores (that haven't already been calculated)
      i = i + 1 # increment index
      slcdist[i] <- distHaversine(c(slc_data$longitude[x], slc_data$latitude[x]),
                           c(slc_data$longitude[y], slc_data$latitude[y]))
      logandist[i] <- distHaversine(c(logan_data$longitude[x], logan_data$latitude[x]),
                           c(logan_data$longitude[y], logan_data$latitude[y]))
      provodist[i] <- distHaversine(c(provo_data$longitude[x], provo_data$latitude[x]),
                           c(provo_data$longitude[y], provo_data$latitude[y]))
      oremdist[i] <- distHaversine(c(orem_data$longitude[x], orem_data$latitude[x]),
                           c(orem_data$longitude[y], orem_data$latitude[y]))
      sjdist[i] <- distHaversine(c(sj_data$longitude[x], sj_data$latitude[x]),
                           c(sj_data$longitude[y], sj_data$latitude[y]))
      farmingtondist[i] <- distHaversine(c(farmington_data$longitude[x], farmington_data$latitude[x]),
                     c(farmington_data$longitude[y], farmington_data$latitude[y]))
      morgandist[i] <- distHaversine(c(morgan_data$longitude[x], morgan_data$latitude[x]),
                           c(morgan_data$longitude[y], morgan_data$latitude[y]))
      wellingtondist[i] <- distHaversine(c(wellington_data$longitude[x], wellington_data$latitude[x]),
                           c(wellington_data$longitude[y], wellington_data$latitude[y]))
      rooseveltdist[i] <- distHaversine(c(roosevelt_data$longitude[x], roosevelt_data$latitude[x]),
                           c(roosevelt_data$longitude[y], roosevelt_data$latitude[y]))
      woodscrossdist[i] <- distHaversine(c(woodscross_data$longitude[x], woodscross_data$latitude[x]),
                           c(woodscross_data$longitude[y], woodscross_data$latitude[y]))
  }
}
```

To calculate the average distance between each store variation per city (distance between store 1 and 2, distance between store 1 and 3, and so on), we decided to implement a nested for-loop. The outer loop iterates through each store and the inner loop iterates through all stores left to calculate the distance between. By this we mean that if we have already calculated the distance between store 1 and store 2, we do not want to calculate the distance between store 2 and store 1 as that would be a duplicate data point. Inside the inner loop, we calculate the distance between the two current stores with the `distHaversine` function. This function calculates the shortest distance between 2 points- in this case, latitude and longitude points. The function returns the calculated distance in meters. We added each calculated distance per city into distance arrays by city, so that we may access the distances at later points in time and calculate relevant sample statistics. It is important to note that these distances do not account for any road accessibility or distances through roads, but rather uses global coordinates to find closest distance between two stores. Ideally, this study would utilize roads to figure out store distances, but unfortunately, this would be too time-consuming for our study.

To view these calculated distances, we created an array and plot of the means:

```{r}
# store all average distances in a new array
all_avg_distances <- c(mean(slcdist), mean(logandist), mean(provodist), mean(oremdist), mean(sjdist), mean(farmingtondist),
                      mean(woodscrossdist), mean(rooseveltdist), mean(morgandist), mean(wellingtondist))

# distance plot
par(mar = c(5.1, 4.1, 4.1, 8.1), xpd=TRUE) # add extra space outside of plot
barplot(all_avg_distances, 
        names.arg = c("SLC", "Provo", "Orem", "S. Jordan", "Logan", "Farmington", "Woods Cross", "Roosevelt", "Morgan", "Wellington"), 
        xlab = "Cities",
        ylab = "Distance in Meters (m)", 
        main = "Average Distance Between Stores by City", 
        col=c("#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0", "#1b98e0",  "#111111", "#111111", "#111111", "#111111", "#111111"), las = 3)
legend("topright", inset=c(-0.3,0),        # add legend to bar plot
       legend = c("Urban Cities", "Rural Cities"),
       fill = c("#1b98e0", "#111111"))
```

As we can see in the Average Distance Between Stores In Cities plot above, the urban cities have similar average distances, where as the rural cities defer by several thousands in store distances. Furthermore, in rural cities, Farmington and Wellington are well over 6000 meters in average distance, where as the others are below the urban areas. Rural areas are smaller in area and so therefore the stores in the cities would be more dense. Which is why we can see Morgan, Roosevelt, and Woods cross have lower distance, but there also could rural areas where overall areas are larger than urban cities due to the nature of farming lands or just more land area per house. This could explain why we see a higher average distance between all types of stores for rural areas in Wellington and Farmington. Wellington and Farmington are bigger in area than the other rural cities. When we calculate average store distances for rural and urban, we get the following:

We calculated the total average distance between stores in urban and rural cities:

```{r}
# average distance in urban cities
urban_avg_dist <- (mean(slcdist) + mean(logandist) + mean(provodist) + mean(oremdist) + mean(sjdist))/5
urban_avg_dist
# average distance in rural cities
rural_avg_dist<- (mean(farmingtondist)+ mean(wellingtondist) + mean(morgandist)+ mean(rooseveltdist)+ mean(woodscrossdist))/5
rural_avg_dist
```

As calculated, urban average store distances are fewer by 500 meters compared to rural store distances. By looking at store average distances between the others, we can determine how dense the stores are in the area from our sample. This helps us give further insight into store accessibility, and with our data, we can see that urban cities have a more consistent distance, where as rural areas are more variable.

Lastly on the topic of average distance summaries, we created a histogram:

```{r}
# total average distances histogram - How does store distance behave for all of Utah?
lattice::histogram(all_avg_distances, breaks = 10,
                   main = paste("Histogram of Total Average Distances Between Stores"),
                   xlab = "Store Distance in Meters (m)", col = "#1b98e0")
```

From the plot, there is a higher frequency of stores that have a distance around 2000-4000 meters. This is above the CDC's distance definition for food deserts in urban cities, however, none of the distances are above the definition for food deserts in rural cities. It is important to note that we calculated the distances between all types of stores including convenience stores, but the definition for food deserts only counts super markets/grocery stores, so we decided it is important to look at the distribution of stores types as well for each city.

# Store Type

The final statistic left to examine was store type. We extracted the total number of store types per city from the datasets, combined the store type totals per city into one dataframe and created yet another bar plot:

```{r}
# store total number of store types per city
saltlakecityTotalStoreTypes <- c(length(slc_data[which(slc_data$store.type == 'Organic Grocery Store'),6]), 
                                 length(slc_data[which(slc_data$store.type == 'Grocery Store'),6]), 
                                 length(slc_data[which(slc_data$store.type == 'Convenience Store'),6]))

provoTotalStoreTypes <- c(length(provo_data[which(provo_data$store.type == 'Organic Grocery Store'),6]),
                          length(provo_data[which(provo_data$store.type == 'Grocery Store'),6]),
                          length(provo_data[which(provo_data$store.type == 'Convenience Store'),6]))

southjordanTotalStoreTypes <- c(length(sj_data[which(sj_data$store.type == 'Organic Grocery Store'),6]), 
                                length(sj_data[which(sj_data$store.type == 'Grocery Store'),6]), 
                                length(sj_data[which(sj_data$store.type == 'Convenience Store'),6]))

oremTotalStoreTypes <- c(length(orem_data[which(orem_data$store.type == 'Organic Grocery Store'),6]), 
                         length(orem_data[which(orem_data$store.type == 'Grocery Store'),6]), 
                         length(orem_data[which(orem_data$store.type == 'Convenience Store'),6]))

loganTotalStoreTypes <- c(length(logan_data[which(logan_data$store.type == 'Organic Grocery Store'),6]), 
                          length(logan_data[which(logan_data$store.type == 'Grocery Store'),6]), 
                          length(logan_data[which(logan_data$store.type == 'Convenience Store'),6]))

wellingtonTotalStoreTypes <- c(length(wellington_data[which(wellington_data$store.type == 'Organic Grocery Store'),6]), 
                               length(wellington_data[which(wellington_data$store.type == 'Grocery Store'),6]), 
                               length(wellington_data[which(wellington_data$store.type == 'Convenience Store'),6]))

morganTotalStoreTypes <- c(length(morgan_data[which(morgan_data$store.type == 'Organic Grocery Store'),6]), 
                           length(morgan_data[which(morgan_data$store.type == 'Grocery Store'),6]), 
                           length(morgan_data[which(morgan_data$store.type == 'Convenience Store'),6]))

farmingtonTotalStoreTypes <- c(length(farmington_data[which(farmington_data$store.type == 'Organic Grocery Store'),6]), 
                               length(farmington_data[which(farmington_data$store.type == 'Grocery Store'),6]), 
                               length(farmington_data[which(farmington_data$store.type == 'Convenience Store'),6]))

rooseveltTotalStoreTypes <- c(length(roosevelt_data[which(roosevelt_data$store.type == 'Organic Grocery Store'),6]), 
                              length(roosevelt_data[which(roosevelt_data$store.type == 'Grocery Store'),6]), 
                              length(roosevelt_data[which(roosevelt_data$store.type == 'Convenience Store'),6]))

woodscrossTotalStoreTypes <- c(length(woodscross_data[which(woodscross_data$store.type == 'Organic Grocery Store'),6]), 
                               length(woodscross_data[which(woodscross_data$store.type == 'Grocery Store'),6]), 
                               length(woodscross_data[which(woodscross_data$store.type == 'Convenience Store'),6]))

# combine vectors using c bind function
totalStoreTypes <- cbind(saltlakecityTotalStoreTypes, provoTotalStoreTypes, oremTotalStoreTypes, southjordanTotalStoreTypes,  
                         loganTotalStoreTypes, farmingtonTotalStoreTypes, woodscrossTotalStoreTypes, rooseveltTotalStoreTypes, 
                         wellingtonTotalStoreTypes, morganTotalStoreTypes)
# plot total store types
par(mar = c(5.1, 4.1, 4.1, 8.1), xpd=TRUE) # add extra space outside of plot
barplot(totalStoreTypes , beside=T, 
        names.arg = c("SLC", "Provo", "Orem", "S. Jordan", "Logan", "Farmington", "Woods Cross", "Roosevelt", "Morgan", "Wellington"), 
        xlab = "Cities",
        ylab = "Stores", 
        main = "Store Types Found in Each City", 
        col=c("#1b98e0", "#111111", "#aaaaaa"), las = 3)
legend("bottomright", inset=c(-0.35,0),        # add legend to bar plot
       legend = c("Organic GS", "Grocery Store", "Convenience S"),
       fill = c("#1b98e0", "#111111", "#aaaaaa"))
```
In this plot, we can see more organic grocery stores in urban cities, but many more convenience stores in rural cities. The data we did sample shows thereâs more grocery stores in general in urban cities, as well as organic grocery stores. In rural cities we found that there was a lot more convenience stores in the data we did sample. This is somewhat representative of the population of rural and urban cities. Looking at which ones are more frequent in the area helps us determine which type of store people are most likely more frequently going to (because of âconvenienceâ). The distance between stores we observed included convenience stores. Morgan and Roosevelt have the highest number of convenience stores as observed in the plot, but when we bring in distances, we saw in our average distance plot that Morgan and Roosevelt also have the smallest average store distances out of all cities. Salt lake city and South Jordan in our sample had no convenience stores hence suggesting that the store type in these two cities have options compared to others.

Store types help us look at what is available in the area. By looking to see if a city has more convenience stores or grocery stores, we can get insight into what is mostly accessible in the area. A higher number of convenience stores also contribute to food deserts.

# Distance Confidence Intervals

For more analysis, since we would like "strong evidence" for the bounds of the population parameter, we will approximate a 95% two-sided confidence interval using a t-approximation and the calculated sample mean and sd. We want to know how confident we can actually be that the mean distance between stores that we calculated for our sample are an accurate representation of the true population. The calculated CLT approximations for the mean distance between stores for each city are shown below:

```{r}
# 95% confidence level - How confident are we that the mean of our sample is an accurate representation of the true population?
t.test(slcdist, conf.level = 0.95)
t.test(provodist, conf.level = 0.95)
t.test(oremdist, conf.level = 0.95)
t.test(sjdist, conf.level = 0.95)
t.test(logandist, conf.level = 0.95)
t.test(farmingtondist, conf.level = 0.95)
t.test(woodscrossdist, conf.level = 0.95)
t.test(rooseveltdist, conf.level = 0.95)
t.test(morgandist, conf.level = 0.95)
t.test(wellingtondist, conf.level = 0.95)
```

For each confidence interval calculated above, we can see the width of the intervals are very wide. A confidence interval indicates where the population parameter is likely to reside. In the case of Salt Lake City, the 95% confidence interval of the mean suggests that we can be 95% confident that the population mean is between 1426.050 meters and 4401.668 meters. This interval has a 2975.618 meter wide gap. Additionally, the borderline distance determining whether or not Salt Lake City is a food desert is 1609 meters- which exists somewhere within this wide range. This seems to be the case for each city's dataset- the wide interval width mean that we cannot really be that confident that the sample statistics we calculated are representative of the entire population. Meaning, Salt Lake City may actually have a much higher or lower average distance between stores that the limitations of this study caused us to be unable to predict.

In addition to calculating confidence intervals for the mean distance for each city, we also wanted to know how confident we can be in comparing our data. In other words; how confident are we that one city actually has a larger between-store distance than another? The calculated CLT distribution is shown below:

```{r}
# create data frame combining all dist
all_distances <- data.frame(SLC = slcdist, PROVO = provodist, OREM = oremdist, SOUTHJORDAN = sjdist, LOGAN = logandist, 
                            FARMINGTON = farmingtondist, WOODSCROSS = woodscrossdist, ROOSEVELT = rooseveltdist, 
                            MORGAN = morgandist, WELLINGTON = wellingtondist)

# calculate conf intervals between all cities store distances - How confident are we that one city actually has a larger between-store distance than another?
all_distances_cis <- apply(all_distances, 1, function(x){t.test(x, conf.level = 0.95)})

# check for overlap, data from list 
df1 <- read.table(text = 
" City	lowerci	Estimate	upperci
SLC	392	1912.751	3433
Provo	748	3607.293	6467
Orem	459	3003.557	5548
SouthJordan	1161	3857.936	6555
Logan	1838	4583.664	7392
Farmington	662	3537.668	6413
WoodsCross	834	3067.96	6969    
Morgan	591	3263.311	5936
Roosevelt	1830	3844.588	5859
Wellington	1462	4370.249	1285.814
", header = TRUE, as.is = TRUE)

ggplot(df1, aes(x = City, y = Estimate, ymin = lowerci, ymax = upperci)) +
  geom_pointrange() +
  ggtitle("Average Distance Between Stores Confidence Interals for Each City")
```

Analyzing the plot of the two-sided 95% confidence interval results shows that the interval bounds for several cities overlapped with the bounds of the means for other cities. This overlap of these bounds decreases the "confidence" we can have for the difference in the mean distances between stores being that significant. So, while we may report that one city has a greater average distance between stores than another in our, the data supporting that difference may not actually be that significant to make such a statement about the entire population.

## Conclusions
